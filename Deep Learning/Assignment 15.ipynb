{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Deep Learning.\n",
    "a. Build a DNN with five hidden layers of 100 neurons each, He initialization, and the\n",
    "ELU activation function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Build a Deep Neural Network\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(input_size,)))\n",
    "\n",
    "# Hidden layers with He initialization and ELU activation\n",
    "for _ in range(5):\n",
    "    model.add(tf.keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'))\n",
    "\n",
    "# Output layer (adjust the activation function and units based on your problem)\n",
    "model.add(tf.keras.layers.Dense(output_size, activation='softmax'))\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Using Adam optimization and early stopping, try training it on MNIST but only on\n",
    "digits 0 to 4, as we will use transfer learning for digits 5 to 9 in the next exercise. You\n",
    "will need a softmax output layer with five neurons, and as always make sure to save\n",
    "checkpoints at regular intervals and save the final model so you can reuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rushabh.Patel2\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 167s 15us/step\n",
      "WARNING:tensorflow:From C:\\Users\\Rushabh.Patel2\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Rushabh.Patel2\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Rushabh.Patel2\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Rushabh.Patel2\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "765/765 [==============================] - 5s 6ms/step - loss: 0.1183 - accuracy: 0.9618 - val_loss: 0.0555 - val_accuracy: 0.9825\n",
      "Epoch 2/50\n",
      "  1/765 [..............................] - ETA: 3s - loss: 0.0103 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rushabh.Patel2\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0579 - accuracy: 0.9812 - val_loss: 0.0657 - val_accuracy: 0.9806\n",
      "Epoch 3/50\n",
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0412 - accuracy: 0.9879 - val_loss: 0.0529 - val_accuracy: 0.9853\n",
      "Epoch 4/50\n",
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0373 - accuracy: 0.9880 - val_loss: 0.0476 - val_accuracy: 0.9842\n",
      "Epoch 5/50\n",
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0283 - accuracy: 0.9904 - val_loss: 0.0358 - val_accuracy: 0.9899\n",
      "Epoch 6/50\n",
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.0582 - val_accuracy: 0.9845\n",
      "Epoch 7/50\n",
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.0446 - val_accuracy: 0.9897\n",
      "Epoch 8/50\n",
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0414 - val_accuracy: 0.9899\n",
      "Epoch 9/50\n",
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.0550 - val_accuracy: 0.9863\n",
      "Epoch 10/50\n",
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0360 - val_accuracy: 0.9915\n",
      "Epoch 11/50\n",
      "765/765 [==============================] - 10s 13ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0295 - val_accuracy: 0.9913\n",
      "Epoch 12/50\n",
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.0438 - val_accuracy: 0.9887\n",
      "Epoch 13/50\n",
      "765/765 [==============================] - 4s 5ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.0381 - val_accuracy: 0.9917\n",
      "Epoch 14/50\n",
      "765/765 [==============================] - 4s 5ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0433 - val_accuracy: 0.9907\n",
      "Epoch 15/50\n",
      "765/765 [==============================] - 4s 5ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0330 - val_accuracy: 0.9925\n",
      "Epoch 16/50\n",
      "765/765 [==============================] - 2s 3ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0500 - val_accuracy: 0.9879\n",
      "Epoch 17/50\n",
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.0416 - val_accuracy: 0.9904\n",
      "Epoch 18/50\n",
      "765/765 [==============================] - 3s 4ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0382 - val_accuracy: 0.9908\n",
      "Epoch 19/50\n",
      "765/765 [==============================] - 2s 3ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0633 - val_accuracy: 0.9900\n",
      "Epoch 20/50\n",
      "765/765 [==============================] - 3s 3ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0516 - val_accuracy: 0.9894\n",
      "Epoch 21/50\n",
      "765/765 [==============================] - 4s 5ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0354 - val_accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Load MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Filter digits 0 to 4\n",
    "train_mask = (train_labels < 5)\n",
    "test_mask = (test_labels < 5)\n",
    "train_images, train_labels = train_images[train_mask], train_labels[train_mask]\n",
    "test_images, test_labels = test_images[test_mask], test_labels[test_mask]\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Build the DNN\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    Dense(5, activation='softmax')  # Softmax output layer with five neurons\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set up callbacks for checkpointing and early stopping\n",
    "checkpoint_cb = ModelCheckpoint(\"model_checkpoint.h5\", save_best_only=True)\n",
    "early_stopping_cb = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=50, validation_split=0.2,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "# Save the final model\n",
    "model.save(\"final_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Tune the hyperparameters using cross-validation and see what precision you can\n",
    "achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ModelCheckpoint\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load MNIST dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m (X_train_full, y_train_full), (X_test, y_test) \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mload_data()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Filter for digits 0 to 4\n",
    "mask_train = (y_train_full <= 4)\n",
    "mask_test = (y_test <= 4)\n",
    "\n",
    "X_train, y_train = X_train_full[mask_train], y_train_full[mask_train]\n",
    "X_test, y_test = X_test[mask_test], y_test[mask_test]\n",
    "\n",
    "# Flatten and normalize the pixel values\n",
    "X_train = X_train.reshape(X_train.shape[0], -1) / 255.0\n",
    "X_test = X_test.reshape(X_test.shape[0], -1) / 255.0\n",
    "\n",
    "# One-hot encode the target labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=5)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=5)\n",
    "\n",
    "# Define the DNN model function\n",
    "def create_dnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='elu', kernel_initializer='he_normal', input_shape=(784,)))\n",
    "    model.add(Dense(100, activation='elu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(100, activation='elu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(100, activation='elu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(100, activation='elu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create and compile the DNN model\n",
    "dnn_model = create_dnn_model()\n",
    "\n",
    "# Set up callbacks for early stopping and model checkpoint\n",
    "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = ModelCheckpoint(\"dnn_model.h5\", save_best_only=True)\n",
    "\n",
    "# Train the model on the training set\n",
    "history = dnn_model.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping_cb, model_checkpoint_cb])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = dnn_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Hyperparameter tuning using cross-validation\n",
    "param_grid = {'batch_size': [32, 64, 128], 'epochs': [50, 100, 150]}\n",
    "model = KerasClassifier(build_fn=create_dnn_model, verbose=0)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='precision_weighted', verbose=2)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding precision score\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best Precision Score: \", grid_result.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
