{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.\tIs it OK to initialize all the weights to the same value as long as that value is selected randomly using He initialization?\n",
    "\n",
    "Initializing all weights to the same value, even if randomly selected using techniques like He initialization, is generally not recommended. While He initialization ensures that the weights are initialized to random values with appropriate scales to prevent gradients from exploding or vanishing during training, initializing all weights to the same value can lead to issues such as symmetry breaking problems.\n",
    "\n",
    "Here's why initializing all weights to the same value is not ideal:\n",
    "\n",
    "1. **Symmetry Breaking**: Initializing all weights to the same value can result in symmetry among neurons in the same layer. This symmetry can cause neurons to compute the same output during forward propagation and receive the same gradients during backpropagation, leading to slow or inefficient training.\n",
    "\n",
    "2. **Reduced Expressiveness**: Neural networks rely on the diversity of weights to learn complex representations from data. If all weights are initialized to the same value, the network's capacity to represent diverse features may be limited, potentially reducing its expressiveness and performance.\n",
    "\n",
    "3. **Vanishing Gradients**: While He initialization helps mitigate the vanishing gradient problem by scaling the weights appropriately, initializing all weights to the same value may exacerbate this issue. If gradients for different neurons become similar due to symmetric weights, the network may struggle to learn effectively, particularly in deeper architectures.\n",
    "\n",
    "4. **Decreased Learning Dynamics**: Initializing all weights to the same value can lead to decreased learning dynamics, as neurons in the network may behave similarly and fail to develop distinct features. This can hinder the network's ability to learn complex patterns and adapt to variations in the data.\n",
    "\n",
    "In summary, while techniques like He initialization ensure that weights are initialized to random values with appropriate scales, it's generally not advisable to initialize all weights to the same value. It's important to maintain diversity among weights to break symmetry, promote efficient learning dynamics, and enable the network to effectively learn complex representations from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.\tIs it OK to initialize the bias terms to 0?\n",
    "\n",
    "Initializing bias terms to 0 is a common practice in neural network initialization and is generally considered acceptable. There are a few reasons for this:\n",
    "\n",
    "1. **Symmetry Breaking**: Unlike weight parameters, which need to be initialized with random values to break symmetry and promote diversity in feature representations, bias terms do not introduce symmetry issues. Initializing bias terms to 0 does not lead to symmetry among neurons and does not hinder the expressiveness of the network.\n",
    "\n",
    "2. **Effect on Learning**: The role of bias terms is to shift the activation function, allowing the model to better fit the data by capturing offset from zero. Initializing bias terms to 0 initially ensures that the network starts with a neutral position, and it will learn the appropriate bias values during training to best fit the data.\n",
    "\n",
    "3. **Gradient Descent**: During training, bias terms are updated along with the weight parameters through backpropagation. Initializing bias terms to 0 does not hinder the effectiveness of gradient descent, as the network adjusts the bias values to minimize the loss function based on the gradients computed during backpropagation.\n",
    "\n",
    "4. **Simplicity and Efficiency**: Initializing bias terms to 0 simplifies the initialization process and reduces the number of hyperparameters that need to be tuned. It also makes the initialization process more computationally efficient, as bias terms do not need to be randomly initialized.\n",
    "\n",
    "However, it's worth noting that initializing bias terms to non-zero values can sometimes improve training stability or convergence speed, especially in certain scenarios or architectures. For example, in networks with highly asymmetric activation functions (e.g., ReLU), initializing bias terms to small positive values might be beneficial. Nonetheless, initializing bias terms to 0 is a common and generally acceptable practice in most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.\tName three advantages of the SELU activation function over ReLU.\n",
    "\n",
    "The Scaled Exponential Linear Unit (SELU) activation function offers several advantages over the Rectified Linear Unit (ReLU) activation function. Here are three key advantages:\n",
    "\n",
    "1. **Self-normalization**:\n",
    "   - One significant advantage of SELU over ReLU is its self-normalizing property. When using SELU, the activations tend to converge towards zero mean and unit variance, which helps stabilize the training process. This self-normalization property allows deep neural networks with many layers to maintain stable activations throughout the network, mitigating issues such as vanishing or exploding gradients.\n",
    "  \n",
    "2. **Avoids Dying ReLU Problem**:\n",
    "   - ReLU neurons can suffer from the \"dying ReLU\" problem, where neurons become inactive (outputting zero) for all inputs with negative weights during training, effectively killing them. This can lead to dead neurons in the network and slow down learning. SELU neurons, on the other hand, avoid this issue due to their smoothness and non-zero output for negative inputs, ensuring that gradients continue to flow during training.\n",
    "   \n",
    "3. **Smooth and Continuous**:\n",
    "   - Unlike ReLU, which has a non-smooth transition at the origin (where the activation abruptly changes from zero to the input value), SELU has a smooth and continuous transition around zero. This smoothness can facilitate gradient-based optimization algorithms, leading to more stable and efficient training.\n",
    "   \n",
    "Overall, the self-normalizing property, avoidance of the dying ReLU problem, and smoothness make SELU a promising activation function for deep neural networks, especially in scenarios where stability and convergence are crucial, such as training very deep architectures or networks with recurrent connections. However, it's important to note that SELU may not always outperform ReLU in every scenario, and its effectiveness depends on factors such as the specific architecture, dataset, and optimization technique used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.\tIn which cases would you want to use each of the following activation functions: SELU, leaky ReLU (and its variants), ReLU, tanh, logistic, and softmax?\n",
    "\n",
    "Different activation functions are suitable for different scenarios depending on the nature of the problem, the architecture of the neural network, and the characteristics of the data. Here's a general guideline on when to use each of the mentioned activation functions:\n",
    "\n",
    "1. **SELU (Scaled Exponential Linear Unit)**:\n",
    "   - Use SELU when building deep neural networks with many layers.\n",
    "   - Particularly effective for feedforward and recurrent neural networks due to its self-normalizing property, which helps stabilize activations and mitigate vanishing/exploding gradients.\n",
    "   - Suitable for architectures where maintaining stable activations throughout the network is crucial, such as in sequence-to-sequence models or deep reinforcement learning.\n",
    "\n",
    "2. **Leaky ReLU and its variants (e.g., Parametric Leaky ReLU, Randomized Leaky ReLU)**:\n",
    "   - Use Leaky ReLU and its variants when training deep neural networks where the standard ReLU may suffer from the \"dying ReLU\" problem.\n",
    "   - Effective in scenarios where a small negative slope for negative inputs helps prevent neurons from becoming inactive.\n",
    "   - Useful when a more flexible activation function than ReLU is desired, allowing a small gradient for negative inputs to facilitate learning.\n",
    "\n",
    "3. **ReLU (Rectified Linear Unit)**:\n",
    "   - Use ReLU as a default choice for most hidden layers in feedforward neural networks.\n",
    "   - Effective in scenarios where sparsity and computational efficiency are desirable, as it only requires simple thresholding operations.\n",
    "   - Suitable for networks with deeper architectures, as it has been widely used and empirically proven to work well in practice.\n",
    "\n",
    "4. **Tanh (Hyperbolic Tangent)**:\n",
    "   - Use tanh when dealing with data that is standardized or normalized between -1 and 1.\n",
    "   - Suitable for recurrent neural networks (RNNs) and architectures where the output range needs to be bounded between -1 and 1.\n",
    "   - Useful when modeling data with symmetrically distributed features around zero, such as image data or audio signals.\n",
    "\n",
    "5. **Logistic (Sigmoid)**:\n",
    "   - Use logistic sigmoid when performing binary classification tasks, where the output needs to be interpreted as probabilities.\n",
    "   - Suitable for the final layer of binary classifiers, where the output range is constrained between 0 and 1, representing the probability of belonging to one of the two classes.\n",
    "   - Effective in scenarios where the decision boundary between classes is nonlinear and needs to be modeled with a smooth transition.\n",
    "\n",
    "6. **Softmax**:\n",
    "   - Use softmax as the final activation function in multi-class classification tasks.\n",
    "   - Suitable for scenarios where the output needs to represent a probability distribution over multiple classes.\n",
    "   - Effective in neural network architectures where the goal is to assign a probability to each class label, such as in image classification or natural language processing tasks like sentiment analysis or named entity recognition.\n",
    "\n",
    "It's important to note that the choice of activation function may require experimentation and tuning based on the specific requirements of the task and the characteristics of the data. Additionally, advancements in neural network architectures and optimization techniques may lead to new activation functions or modifications to existing ones that are better suited for certain scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.\tWhat may happen if you set the momentum hyperparameter too close to 1 (e.g., 0.99999) when using an SGD optimizer?\n",
    "\n",
    "Setting the momentum hyperparameter too close to 1 (e.g., 0.99999) when using Stochastic Gradient Descent (SGD) optimizer can lead to several potential issues:\n",
    "\n",
    "1. **Overshooting and Instability**: Momentum helps accelerate SGD in relevant directions and dampens oscillations. When momentum is set too close to 1, it means that the gradient updates from previous time steps contribute heavily to the current update. This can cause the optimizer to overshoot the minimum or oscillate around it, leading to instability in training and slower convergence.\n",
    "\n",
    "2. **Difficulty in Convergence**: Extremely high momentum values can make it difficult for the optimizer to converge to a good solution. The large momentum effectively smooths out the updates, making it harder for the optimizer to escape from local minima or saddle points in the optimization landscape.\n",
    "\n",
    "3. **Poor Generalization**: Overly high momentum can hinder the optimizer's ability to explore the parameter space effectively. This may lead to poor generalization, as the model might converge to a suboptimal solution that performs well on the training data but fails to generalize to unseen data.\n",
    "\n",
    "4. **Oscillatory Behavior**: Setting momentum too close to 1 can introduce oscillatory behavior in the optimization process. The optimizer may overshoot the minimum, then swing back and overshoot again, leading to a zig-zagging trajectory in the parameter space.\n",
    "\n",
    "5. **Numerical Stability Issues**: Extremely high momentum values may lead to numerical stability issues during training. The accumulation of large gradients from previous time steps can result in large updates to the model parameters, potentially causing overflow or underflow errors in numerical computations.\n",
    "\n",
    "In summary, setting the momentum hyperparameter too close to 1 in SGD optimization can lead to instability, slow convergence, poor generalization, oscillatory behavior, and numerical stability issues. It's important to choose an appropriate momentum value based on the characteristics of the optimization problem and to experiment with different values to find the one that yields the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6.\tName three ways you can produce a sparse model\n",
    "\n",
    "Producing a sparse model, where many of the parameters are set to zero, can be beneficial for reducing memory footprint, speeding up inference, and improving model interpretability. Here are three ways to produce a sparse model:\n",
    "\n",
    "1. **Regularization Techniques**:\n",
    "   - **L1 Regularization (Lasso)**: By adding an L1 penalty term to the loss function during training, the optimization process tends to shrink the weights towards zero. This encourages sparsity in the model, as many weights end up being exactly zero. L1 regularization is particularly effective in producing sparse models when combined with optimization algorithms such as stochastic gradient descent.\n",
    "   - **Group Lasso Regularization**: Group Lasso extends L1 regularization to encourage entire groups of related weights to be exactly zero. This is useful when certain groups of weights are expected to have similar importance or when there are inherent group structures in the data.\n",
    "   - **Elastic Net Regularization**: Elastic Net combines L1 and L2 regularization, allowing for a balance between the sparsity-inducing property of L1 regularization and the ridge regression property of L2 regularization. This can lead to improved performance in scenarios where there are many correlated features.\n",
    "\n",
    "2. **Pruning Techniques**:\n",
    "   - **Magnitude-based Pruning**: After training a model, weights below a certain threshold are set to zero, effectively pruning away connections that contribute less to the overall model performance. Magnitude-based pruning is simple to implement and can be applied iteratively to achieve desired sparsity levels.\n",
    "   - **Iterative Pruning Algorithms**: Iterative pruning algorithms iteratively train and prune the model, removing less important connections and retraining the remaining ones. This process continues until the desired sparsity level is achieved. Examples include Optimal Brain Damage (OBD) and Optimal Brain Surgeon (OBS).\n",
    "\n",
    "3. **Sparse Architectures**:\n",
    "   - **Sparse Neural Networks**: Architectures specifically designed to produce sparse activations or connections can inherently lead to sparse models. For example, networks with sparsely connected layers, such as Sparse Autoencoders or Sparse Neural Networks, can naturally produce sparse representations during training.\n",
    "   - **Attention Mechanisms**: Attention mechanisms in models like Transformers can lead to sparse attention patterns, where only a subset of inputs are attended to for each output. This sparsity can be beneficial for reducing computation and memory requirements, particularly in scenarios with long sequences.\n",
    "\n",
    "By utilizing these techniques, practitioners can produce sparse models that retain performance while reducing memory and computational requirements, enabling more efficient deployment and improving model interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7.\tDoes dropout slow down training? Does it slow down inference (i.e., making predictions on new instances)? What about MC Dropout?\n",
    "\n",
    "Dropout is a regularization technique commonly used during training to prevent overfitting in neural networks. While dropout does introduce additional computational overhead during training, its impact on training speed and inference time can vary depending on the implementation and specific circumstances.\n",
    "\n",
    "Here's how dropout may affect training and inference:\n",
    "\n",
    "1. **Training Speed**:\n",
    "   - Dropout can slow down training to some extent because it requires additional computations during each training iteration. During dropout, a random subset of neurons is set to zero with a specified dropout probability, and this process needs to be performed for each training sample and each layer in the network.\n",
    "   - However, the slowdown introduced by dropout is generally modest, especially when compared to other computationally intensive tasks such as forward and backward passes through deep neural networks. In practice, dropout is often used as a regularizer without significant impact on training speed.\n",
    "\n",
    "2. **Inference Speed**:\n",
    "   - Dropout does not typically slow down inference, as dropout is only applied during training and is turned off during inference. During inference, all neurons are active, and there is no dropout applied, so the computational overhead introduced by dropout is not present.\n",
    "   - In fact, dropout can sometimes speed up inference by acting as an ensemble technique, where multiple models with different dropout masks are averaged together to produce more robust predictions.\n",
    "\n",
    "3. **MC Dropout (Monte Carlo Dropout)**:\n",
    "   - MC Dropout is an extension of dropout that can be used during inference to obtain uncertainty estimates from neural networks. It involves running inference multiple times with dropout turned on and using the variability in predictions across these runs to estimate uncertainty.\n",
    "   - MC Dropout can slow down inference because it requires running inference multiple times to obtain uncertainty estimates. Each inference run involves applying dropout and making predictions, and this process needs to be repeated multiple times to obtain reliable uncertainty estimates.\n",
    "   - While MC Dropout can introduce additional computational overhead during inference, it provides valuable uncertainty estimates that can be useful in various applications, such as in uncertainty-aware decision making or in detecting out-of-distribution samples.\n",
    "\n",
    "In summary, dropout may introduce some computational overhead during training, but its impact on training speed is generally modest. Dropout does not typically slow down inference, as it is only applied during training. However, MC Dropout, which is used for uncertainty estimation during inference, can introduce additional computational overhead due to the need to run inference multiple times with dropout turned on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8.\tPractice training a deep neural network on the CIFAR10 image dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the ELU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dell8\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 167s 1us/step\n",
      "WARNING:tensorflow:From C:\\Users\\dell8\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell8\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dell8\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\dell8\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dell8\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      " 230/1563 [===>..........................] - ETA: 29s - loss: 2.3172 - accuracy: 0.1543"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     34\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:1798\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1796\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1798\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1799\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m         ):\n\u001b[0;32m   1806\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\data_adapter.py:1411\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1411\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1412\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1413\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1416\u001b[0m )\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:689\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    690\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    691\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:839\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \n\u001b[0;32m    832\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 839\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:818\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 818\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    821\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    822\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    823\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    824\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    825\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    826\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:808\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    807\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 808\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:535\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    534\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 535\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    538\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.activations import elu\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Define the DNN architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(32, 32, 3)))  # Flatten input images\n",
    "initializer = HeNormal()  # He initialization\n",
    "activation = elu  # ELU activation function\n",
    "\n",
    "# Add 20 hidden layers with 100 neurons each\n",
    "for _ in range(20):\n",
    "    model.add(layers.Dense(100, kernel_initializer=initializer, activation=activation))\n",
    "\n",
    "# Add output layer with softmax activation for multi-class classification\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
